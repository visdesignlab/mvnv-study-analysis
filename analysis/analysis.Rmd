---
title: "analysis"
author: '@laneharrison'
date: "8/23/2019"
output: html_document
---

## Setup

```{r setup}
library(tidyverse)
library(ggridges)
library(pwr) 
library(grid)
library(gtable)


library(tidybayes)
library(cowplot)
library(broom)

theme_set(theme_tidybayes() + panel_border() + background_grid())


df <- read.csv("../results/pilot/CSV/TidyR.csv")
```


## Data Cleaning / Types

```{r}

df_acc <- df %>% 
  filter(measure=="accuracy") 

df_acc$value = as.numeric( as.character(df_acc$value ))


df_acc
```

## Quick Check Charts

95% CIs + jitter (don't trust those point positions)

```{r}

df %>% 
  filter(measure=="accuracy") %>% 
  mutate( value = as.numeric( as.character(value)) ) %>% 
  ggplot( aes(x=taskId, y=value) ) +
    geom_jitter( alpha = 0.2, width=0.1, height=0.3 ) + 
    stat_summary(fun.data = "mean_cl_boot", colour = "red", size = 0.5, position = position_nudge(x=0.25, y=0), alpha=0.5) +
  coord_flip() +
    facet_grid(. ~ visType)


```

we can do the same with distributions, ridges

```{r}
df %>% 
  filter(measure=="accuracy") %>% 
  mutate( value = as.numeric( as.character(value)) ) %>% 
  ggplot( aes(x=value, y=taskId) ) +
    geom_density_ridges() +
    facet_grid(. ~ visType)

```


, and density plots (look meh-- could probably combine + color for a better look)

```{r, fig.height=10, fig.width=10}

df %>% 
  filter(measure=="accuracy") %>% 
  mutate( value = as.numeric( as.character(value)) ) %>% 
  ggplot( aes(value) ) +
    geom_density( alpha = 0.2 ) +
    facet_grid(taskId ~ visType)

```


## Power Analysis

first, we copy over a trusty old function (h/t Mia)
```{r}

powerAnalysisGraph <- function(m1, m2, stdev, iterNum=15){
  # stdev <- sd_duration.median
  # m1 <- mean(search$duration.median)
  # m2 <- mean(nonsearch$duration.median)
  # # m1 <- mean(foresight$duration.median)
  # # m2 <- mean(nonsearch$duration.median)
  
  iteration <- 15
  
  difference <- 0
  effectSize <- 0
  numParticipants <- 0
  
  for(step in 1:iteration)
  {
    difference[step] <- abs(m1 - m2) * (0.9 ^ (step-1))
    effectSize[step] <- difference[step] / stdev
    numParticipants[step] <- pwr.t.test( 
      d=effectSize[step], 
      sig.level=.05, 
      power=0.8, 
      type="two.sample", 
      alternative="greater" 
    )$n * 1.15 * 2
  }
  
  #dual axis code online: https://rpubs.com/kohske/dual_axis_in_ggplot2
  grid.newpage()
  
  pw <- data.frame(difference=difference, numParticipants=numParticipants, effectSize=effectSize)
  p1 <- ggplot(pw,aes(x=difference)) + geom_line(aes(y = numParticipants)) +
    scale_y_continuous(breaks = pretty(pw$numParticipants, n = 10))
  p2<- ggplot(pw,aes(x=difference)) + geom_line(aes(y = effectSize)) +
    theme(panel.background = element_rect(fill = NA))+
    scale_y_continuous(breaks = pretty(pw$effectSize, n = 10))
  p2
  
  # extract gtable
  g1 <- ggplot_gtable(ggplot_build(p1))
  g2 <- ggplot_gtable(ggplot_build(p2))
  
  # overlap the panel of 2nd plot on that of 1st plot
  pp <- c(subset(g1$layout, name == "panel", se = t:r))
  g <- gtable_add_grob(g1, g2$grobs[[which(g2$layout$name == "panel")]], pp$t, pp$l, pp$b, pp$l)
  
  # axis tweaks
  ia <- which(g2$layout$name == "axis-l")
  ga <- g2$grobs[[ia]]
  ax <- ga$children[[2]]
  ax$widths <- rev(ax$widths)
  ax$grobs <- rev(ax$grobs)
  ax$grobs[[1]]$x <- ax$grobs[[1]]$x - unit(1, "npc") + unit(0.15, "cm")
  g <- gtable_add_cols(g, g2$widths[g2$layout[ia, ]$l], length(g$widths) - 1)
  g <- gtable_add_grob(g, ax, pp$t, length(g$widths) - 1, pp$b)
  
  # draw it
  grid.draw(g)
}

```


then, we test it out with some parameters estimated by eye from our charts so far

```{r}
# task 8 (reading values from graph, could do exact later)
powerAnalysisGraph(0.5, 0.6, 0.25)

# task 13 (reading values from graph, could do exact later)
powerAnalysisGraph(0.2, 0.4, 0.10)
```

Now we want to get better estimates for parameters.
We need Means from each group, on each task, and a pooled stdev.

```{r}

# task 08
sd_t08 = df_acc %>% 
  filter(taskId == "S-task08") %>% 
  summarise(
    stdev = sd(value)
  )

m_nl_t08 = df_acc %>% 
  filter(taskId == "S-task08" & visType == "nodeLink") %>% 
  summarise(
    mean = mean(value)
  )

m_adj_t08 = df_acc %>% 
  filter(taskId == "S-task08" & visType == "adjMatrix") %>% 
  summarise(
    mean = mean(value)
  )

# task 13
sd_t13 = df_acc %>% 
  filter(taskId == "S-task13") %>% 
  summarise(
    stdev = sd(value)
  )

m_nl_t13 = df_acc %>% 
  filter(taskId == "S-task13" & visType == "nodeLink") %>% 
  summarise(
    mean = mean(value)
  )

m_adj_t13 = df_acc %>% 
  filter(taskId == "S-task13" & visType == "adjMatrix") %>% 
  summarise(
    mean = mean(value)
  )

```
... and now some more accurate power analysis graphs

```{r}

powerAnalysisGraph(m_adj_t08[,1], m_nl_t08[,1], sd_t08[,1])

powerAnalysisGraph(m_adj_t13[,1], m_nl_t13[,1], sd_t13[,1])

```



Interpreting the task 13 graph: 
"Given no changes in Means or pooled stdev, and assuming a t-test, you'd need ~225 people total to find a medium effect size."


## Rank-style tests?

Given the data isn't technically continuous at the measurement level, we might consider non-parametric tests


## Tidybayes-style eye plots (in progress + may be abandoned)

```{r}
# df %>% 
#   filter(measure=="accuracy") %>% 
#   mutate( value = as.numeric(value) ) %>% 
#   ggplot( aes(x=taskId, dist="norm", arg1=value) ) +
#   geom_halfeyeh() +
  


m_acc = lm(value ~ taskId, data = df_acc)

summary(m_acc)

tidy(m_acc)

m_acc %>%
  tidy() %>%
  ggplot() +
  geom_halfeyeh( aes(x=term, y=estimate)) 


```


